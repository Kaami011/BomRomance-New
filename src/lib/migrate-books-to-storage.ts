/**
 * Script de migraÃ§Ã£o: Livros mockados â†’ Supabase + Storage
 * 
 * Este script:
 * 1. LÃª os livros mockados de src/data/mockBooks.ts
 * 2. Faz upsert em public.books com metadados
 * 3. Para cada capÃ­tulo:
 *    - Salva conteÃºdo completo no Storage (bucket: chapters)
 *    - Gera preview_text (primeiros 400 caracteres)
 *    - Faz upsert em public.chapters com metadados + path do Storage
 * 
 * Uso: Chamar via API route /api/admin/migrate-books
 */

import { supabase } from './supabase'
import { mockBooks } from '@/data/mockBooks'
import { mockChapters } from '@/data/mockChapters'

interface MigrationResult {
  success: boolean
  booksProcessed: number
  chaptersProcessed: number
  errors: string[]
}

export async function migrateBooksToStorage(): Promise<MigrationResult> {
  const result: MigrationResult = {
    success: true,
    booksProcessed: 0,
    chaptersProcessed: 0,
    errors: []
  }

  console.log('ðŸš€ Iniciando migraÃ§Ã£o de livros para Supabase + Storage...')

  for (const book of mockBooks) {
    try {
      console.log(`ðŸ“š Processando livro: ${book.title}`)

      // 1. Preparar dados do livro
      const bookData = {
        id: book.id,
        title: book.title,
        author: book.author,
        slug: book.id, // SerÃ¡ gerado automaticamente pelo trigger
        description: book.description,
        cover_url: book.cover_image,
        total_views: book.total_views,
        total_chapters: book.total_chapters,
        status: book.status,
        is_original: false, // Livros mockados nÃ£o sÃ£o originais
        is_premium: true, // Por padrÃ£o, livros sÃ£o premium
        created_at: book.created_at,
        updated_at: book.updated_at
      }

      // 2. Upsert do livro
      const { error: bookError } = await supabase
        .from('books')
        .upsert(bookData, { onConflict: 'id' })

      if (bookError) {
        result.errors.push(`Erro ao inserir livro ${book.title}: ${bookError.message}`)
        continue
      }

      result.booksProcessed++
      console.log(`âœ… Livro ${book.title} inserido/atualizado`)

      // 3. Processar capÃ­tulos
      const chapters = mockChapters[book.id] || []
      console.log(`ðŸ“– Processando ${chapters.length} capÃ­tulos...`)

      for (const chapter of chapters) {
        try {
          // 3.1. Gerar preview (primeiros 400 caracteres)
          const previewText = chapter.content
            ? chapter.content.substring(0, 400) + '...'
            : ''

          // 3.2. Preparar conteÃºdo completo para o Storage
          const chapterContent = {
            bookId: book.id,
            chapterIndex: chapter.chapter_number,
            title: chapter.title,
            content: chapter.content
          }

          // 3.3. Definir path no Storage
          const storagePath = `${book.id}/chapter_${chapter.chapter_number}.json`

          // 3.4. Upload para o Storage
          const { error: uploadError } = await supabase.storage
            .from('chapters')
            .upload(storagePath, JSON.stringify(chapterContent, null, 2), {
              contentType: 'application/json',
              upsert: true // Sobrescrever se jÃ¡ existir
            })

          if (uploadError) {
            result.errors.push(
              `Erro ao fazer upload do capÃ­tulo ${chapter.chapter_number} do livro ${book.title}: ${uploadError.message}`
            )
            continue
          }

          // 3.5. Preparar dados do capÃ­tulo para o banco
          const chapterData = {
            id: chapter.id,
            book_id: book.id,
            chapter_number: chapter.chapter_number,
            title: chapter.title,
            content: null, // NÃ£o salvar conteÃºdo completo no Postgres
            preview_text: previewText,
            content_storage_path: storagePath,
            views: chapter.views,
            is_premium: chapter.is_premium,
            created_at: chapter.created_at,
            updated_at: chapter.created_at
          }

          // 3.6. Upsert do capÃ­tulo
          const { error: chapterError } = await supabase
            .from('chapters')
            .upsert(chapterData, { onConflict: 'id' })

          if (chapterError) {
            result.errors.push(
              `Erro ao inserir capÃ­tulo ${chapter.chapter_number} do livro ${book.title}: ${chapterError.message}`
            )
            continue
          }

          result.chaptersProcessed++
          
          // Log a cada 10 capÃ­tulos
          if (chapter.chapter_number % 10 === 0) {
            console.log(`  âœ… ${chapter.chapter_number} capÃ­tulos processados...`)
          }
        } catch (chapterError: any) {
          result.errors.push(
            `Erro ao processar capÃ­tulo ${chapter.chapter_number} do livro ${book.title}: ${chapterError.message}`
          )
        }
      }

      console.log(`âœ… Todos os capÃ­tulos de ${book.title} processados`)
    } catch (bookError: any) {
      result.errors.push(`Erro ao processar livro ${book.title}: ${bookError.message}`)
      result.success = false
    }
  }

  console.log('\nðŸ“Š Resumo da migraÃ§Ã£o:')
  console.log(`âœ… Livros processados: ${result.booksProcessed}/${mockBooks.length}`)
  console.log(`âœ… CapÃ­tulos processados: ${result.chaptersProcessed}`)
  console.log(`âŒ Erros: ${result.errors.length}`)

  if (result.errors.length > 0) {
    console.log('\nâŒ Erros encontrados:')
    result.errors.forEach((error, index) => {
      console.log(`${index + 1}. ${error}`)
    })
    result.success = false
  }

  return result
}
